{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tY9jL20Ehl8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import datetime\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download the stock dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7g4SCz2CEoLf"
      },
      "outputs": [],
      "source": [
        "#the start and end date\n",
        "start_date = dt.datetime(2013,4,1)\n",
        "end_date = dt.datetime(2024,5,3)\n",
        "\n",
        "#loading from yahoo finance\n",
        "data = yf.download(\"GOOGL\",start_date, end_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhd9SzrLFraS"
      },
      "source": [
        "Print the first 5 rows to get a brief overview of the data. If you can't remember the name of the function, think about what your gf should give you every night."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOYHMrR1FHaj"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DVQYeOlEwLN"
      },
      "source": [
        "# Preprocessing steps\n",
        "\n",
        "1. Only select the column \"Close\", bc we only care about that data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtiEOCssGbWk"
      },
      "source": [
        "2. Plot the column with matplotlib to see the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm7G9ZB_Gf1B"
      },
      "source": [
        "3. Write a function to convert a string to a datetime object. The date string looks like that: \"2014-04-01\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwRxAZUQGiI9"
      },
      "outputs": [],
      "source": [
        "def str_to_datetime(s):\n",
        "  # Split the string in 3 parts with '-' as a delimiter\n",
        "  split = # TODO\n",
        "  year, month, day = # TODO\n",
        "  return datetime.datetime(year=year, month=month, day=day)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG298iCrGkd0"
      },
      "source": [
        "# Data preparation\n",
        "\n",
        "This function creates multiple subsets with a specific length n. This is needed to convert the problem into a supervised learning problem. We have a target date and n-values before the close price of the target date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTNPM7RMGxKN"
      },
      "outputs": [],
      "source": [
        "def df_to_windowed_df(dataframe, first_date_str, last_date_str, n=3):\n",
        "  first_date = str_to_datetime(first_date_str)\n",
        "  last_date  = str_to_datetime(last_date_str)\n",
        "\n",
        "  target_date = first_date\n",
        "\n",
        "  dates = []\n",
        "  X, Y = [], []\n",
        "\n",
        "  last_time = False\n",
        "  while True:\n",
        "    df_subset = dataframe.loc[:target_date].tail(n+1)\n",
        "\n",
        "    if len(df_subset) != n+1:\n",
        "      print(f'Error: Window of size {n} is too large for date {target_date}')\n",
        "      return\n",
        "\n",
        "    values = df_subset['Close'].to_numpy()\n",
        "    x, y = values[:-1], values[-1]\n",
        "\n",
        "    dates.append(target_date)\n",
        "    X.append(x)\n",
        "    Y.append(y)\n",
        "\n",
        "    next_week = dataframe.loc[target_date:target_date+datetime.timedelta(days=7)]\n",
        "    next_datetime_str = str(next_week.head(2).tail(1).index.values[0])\n",
        "    next_date_str = next_datetime_str.split('T')[0]\n",
        "    year_month_day = next_date_str.split('-')\n",
        "    year, month, day = year_month_day\n",
        "    next_date = datetime.datetime(day=int(day), month=int(month), year=int(year))\n",
        "\n",
        "    if last_time:\n",
        "      break\n",
        "\n",
        "    target_date = next_date\n",
        "\n",
        "    if target_date == last_date:\n",
        "      last_time = True\n",
        "\n",
        "  ret_df = pd.DataFrame({})\n",
        "  ret_df['Target Date'] = dates\n",
        "\n",
        "  X = np.array(X)\n",
        "  for i in range(0, n):\n",
        "    X[:, i]\n",
        "    ret_df[f'Target-{n-i}'] = X[:, i]\n",
        "\n",
        "  ret_df['Target'] = Y\n",
        "\n",
        "  return ret_df\n",
        "\n",
        "def windowed_df_to_date_X_y(windowed_dataframe):\n",
        "  df_as_np = windowed_dataframe.to_numpy()\n",
        "\n",
        "  dates = df_as_np[:, 0]\n",
        "\n",
        "  middle_matrix = df_as_np[:, 1:-1]\n",
        "  X = middle_matrix.reshape((len(dates), middle_matrix.shape[1], 1))\n",
        "\n",
        "  Y = df_as_np[:, -1]\n",
        "\n",
        "  return dates, X.astype(np.float32), Y.astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BukTRvXBG9LR"
      },
      "source": [
        "Example: Window size of 5 and the data between 2018-04-01 and 2024-05-02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFNR7IuEHNeW"
      },
      "outputs": [],
      "source": [
        "WINDOW_SIZE = 5\n",
        "# Start day: '2018-04-01', last day: '2024-05-02'\n",
        "windowed_df = df_to_windowed_df(data,\n",
        "                                \"2018-04-01\",\n",
        "                                \"2024-05-02\",\n",
        "                                WINDOW_SIZE)\n",
        "print(windowed_df)\n",
        "\n",
        "# Extract dates, x and y\n",
        "dates, X, y = windowed_df_to_date_X_y(windowed_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDnfXYDpJIuV"
      },
      "source": [
        "2. Divide the dataset into training (90%), validation (5%) and test(5%) set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvga-V8xJakF"
      },
      "outputs": [],
      "source": [
        "dates_train, X_train, y_train = #TODO\n",
        "\n",
        "dates_val, X_val, y_val = #TODO\n",
        "dates_test, X_test, y_test = #TODO\n",
        "\n",
        "\n",
        "plt.plot(dates_train, y_train)\n",
        "plt.plot(dates_val, y_val)\n",
        "plt.plot(dates_test, y_test)\n",
        "\n",
        "plt.legend(['Train', 'Validation', 'Test'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n47cXJ-IJmSw"
      },
      "source": [
        "# Train the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd20ssiMJvvT"
      },
      "source": [
        "1. Create a sequential model with an input layer that has the size of the window (WINDOW_SIZE), an LSTM layer with 64 neurons, a dense layer with 32 neurons and Relu activation function and a final dense layer with 1 neuron."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngGHAOXWJov3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "MAX_EPOCHS = 30\n",
        "\n",
        "\n",
        "model = Sequential([layers.Input((WINDOW_SIZE, 1)),\n",
        "                    layers.LSTM(),\n",
        "                    layers.Dense(),\n",
        "                    layers.Dense()])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-JJUf32Kq1D"
      },
      "source": [
        "2. Compile the model with \"mse\" as loss function, the optimizer is gonna be \"Adam\" with a learning rate of 0.001 and the metrics are \"mean_absolute_error\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_H9qNmtLm7Z"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(loss='',\n",
        "              optimizer=,\n",
        "              metrics=['mean_absolute_error'])\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=MAX_EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr3OPkJML653"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fX5CZD2L-Nn"
      },
      "source": [
        "1. Predict the stock price on the validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCHmTC5mMHMe"
      },
      "outputs": [],
      "source": [
        "val_predictions = #TODO\n",
        "\n",
        "plt.plot(dates_val, val_predictions)\n",
        "plt.plot(dates_val, y_val)\n",
        "plt.legend(['Validation Predictions', 'Validation Observations'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATD9-K3hMYbb"
      },
      "source": [
        "2. Predict the stock price on the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNXAkFkaMeZI"
      },
      "outputs": [],
      "source": [
        "test_predictions = # TODO\n",
        "\n",
        "plt.plot(dates_test, test_predictions)\n",
        "plt.plot(dates_test, y_test)\n",
        "plt.legend(['Testing Predictions', 'Testing Observations'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmdlGJ1oMiK8"
      },
      "source": [
        "Overview of all predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzpYzuvYMjNH"
      },
      "outputs": [],
      "source": [
        "plt.plot(dates_val, val_predictions)\n",
        "plt.plot(dates_val, y_val)\n",
        "plt.plot(dates_test, test_predictions)\n",
        "plt.plot(dates_test, y_test)\n",
        "plt.legend(['Validation Predictions',\n",
        "            'Validation Observations',\n",
        "            'Testing Predictions',\n",
        "            'Testing Observations'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
